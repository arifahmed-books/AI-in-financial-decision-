{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681fa55c-3d66-404d-9989-8fef6854e299",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4327a35-c161-4509-b649-c7b04ec7b684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "from docx import Document\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac154e-766b-4410-b220-f53e7d8e586d",
   "metadata": {},
   "source": [
    "### Download data file (one time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba708c80-38f9-4239-bdb8-ac695d637ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\veena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\veena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\veena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\veena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\veena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data (only once. Remove the # sign to run the code)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea6ab6-dd88-4110-abf0-f8f98f6ac2e8",
   "metadata": {},
   "source": [
    "### Customize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717058d3-dfe4-4761-a3cb-b46b17d3c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize parameters\n",
    "\n",
    "my_similarity_threshold=0.6\n",
    "my_report=\"0906 NLP_Compliance_Report.docx\"\n",
    "\n",
    "my_policy_clauses=  [\n",
    "    \"The institution shall maintain client data for a minimum of 3 years, unless otherwise mandated by the jurisdiction.\",\n",
    "    \"All transactions above $10,000 must be reported to the compliance officer within 24 hours.\",\n",
    "    \"Sensitive employee information may be disclosed only upon executive approval.\",\n",
    "    \"No monitoring is required for accounts inactive for more than 12 months.\",\n",
    "    \"Customer complaints will not be logged if received verbally without supporting documentation.\"\n",
    "]\n",
    "\n",
    "my_regulatory_clauses = [\n",
    "    \"Client data must be retained for at least 5 years.\",\n",
    "    \"All cash transactions above $10,000 must be reported immediately.\",\n",
    "    \"Disclosure of employee information must be governed by consent and legal necessity.\",\n",
    "    \"Accounts inactive for more than 6 months must undergo periodic review.\",\n",
    "    \"Customer complaints must be logged and responded to regardless of format.\"\n",
    "]\n",
    "my_red_flags=[\"unless\", \"not required\", \"only upon\", \"no monitoring\", \"not be logged\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f6920-5f7a-477d-b57a-ae8331d4150f",
   "metadata": {},
   "source": [
    "### Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5155b59-9cf8-4f5b-9ff1-51c0a4c5df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal Policy Clauses\n",
    "policy_clauses = my_policy_clauses\n",
    "\n",
    "# Regulatory Requirements\n",
    "regulatory_requirements = my_regulatory_clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933df3dd-094e-48f6-be5b-344fef0877dd",
   "metadata": {},
   "source": [
    "### Prepare and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1534cf4c-55e2-4423-9e5b-04846f494d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Tokenize, lowercase, remove stopwords, and lemmatize the input text.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [w for w in tokens if w not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w) for w in filtered_tokens]\n",
    "    return lemmatized\n",
    "\n",
    "def sentence_similarity(sent1, sent2):\n",
    "    \"\"\"Return similarity ratio between two sentences.\"\"\"\n",
    "    return SequenceMatcher(None, sent1, sent2).ratio()\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    tree = ne_chunk(tags, binary=False)\n",
    "\n",
    "    entities = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            entity_name = \" \".join([token for token, pos in subtree.leaves()])\n",
    "            entity_type = subtree.label()\n",
    "            entities.append(f\"{entity_name} ({entity_type})\")\n",
    "    return entities\n",
    "\n",
    "\n",
    "# Red Flag Phrases and Similarity Threshold\n",
    "red_flags = my_red_flags\n",
    "SIMILARITY_THRESHOLD = my_similarity_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7c61c-662e-433d-b6d6-fc43cf0842f1",
   "metadata": {},
   "source": [
    "### Run analysis and prepare and save report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9f1f07-766e-4cbd-babf-7fb37872338b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "Compliance Monitoring NLP Report\n",
      "===========================\n",
      "\n",
      "Clause 1:\n",
      "Text: The institution shall maintain client data for a minimum of 3 years, unless otherwise mandated by the jurisdiction.\n",
      "Preprocessed Tokens: ['institution', 'shall', 'maintain', 'client', 'data', 'minimum', 'year', 'unless', 'otherwise', 'mandated', 'jurisdiction']\n",
      "Named Entities: None\n",
      "Red Flag Phrase Detected: 'unless'\n",
      "No strong match found in regulatory requirements. Review recommended.\n",
      "------------------------------------------------------------\n",
      "Clause 2:\n",
      "Text: All transactions above $10,000 must be reported to the compliance officer within 24 hours.\n",
      "Preprocessed Tokens: ['transaction', 'must', 'reported', 'compliance', 'officer', 'within', 'hour']\n",
      "Named Entities: None\n",
      "No red flag phrases detected.\n",
      "Matches Regulation (Similarity: 0.68): All cash transactions above $10,000 must be reported immediately.\n",
      "------------------------------------------------------------\n",
      "Clause 3:\n",
      "Text: Sensitive employee information may be disclosed only upon executive approval.\n",
      "Preprocessed Tokens: ['sensitive', 'employee', 'information', 'may', 'disclosed', 'upon', 'executive', 'approval']\n",
      "Named Entities: None\n",
      "Red Flag Phrase Detected: 'only upon'\n",
      "No strong match found in regulatory requirements. Review recommended.\n",
      "------------------------------------------------------------\n",
      "Clause 4:\n",
      "Text: No monitoring is required for accounts inactive for more than 12 months.\n",
      "Preprocessed Tokens: ['monitoring', 'required', 'account', 'inactive', 'month']\n",
      "Named Entities: None\n",
      "Red Flag Phrase Detected: 'no monitoring'\n",
      "No strong match found in regulatory requirements. Review recommended.\n",
      "------------------------------------------------------------\n",
      "Clause 5:\n",
      "Text: Customer complaints will not be logged if received verbally without supporting documentation.\n",
      "Preprocessed Tokens: ['customer', 'complaint', 'logged', 'received', 'verbally', 'without', 'supporting', 'documentation']\n",
      "Named Entities: Customer (GPE)\n",
      "Red Flag Phrase Detected: 'not be logged'\n",
      "Matches Regulation (Similarity: 0.60): Customer complaints must be logged and responded to regardless of format.\n",
      "------------------------------------------------------------\n",
      "\n",
      " Report saved as 0906 NLP_Compliance_Report.docx\n"
     ]
    }
   ],
   "source": [
    "# Prepare Word Document and Console Output\n",
    "doc = Document()\n",
    "doc.add_heading('Compliance Monitoring NLP Report', 0)\n",
    "\n",
    "print(\"\\n===========================\\nCompliance Monitoring NLP Report\\n===========================\\n\")\n",
    "\n",
    "for i, clause in enumerate(policy_clauses):\n",
    "    header = f\"Clause {i+1}:\"\n",
    "    print(header)\n",
    "    doc.add_heading(header, level=1)\n",
    "\n",
    "    print(\"Text:\", clause)\n",
    "    doc.add_paragraph(\"Text: \" + clause)\n",
    "\n",
    "    # Preprocessing\n",
    "    tokens = preprocess_text(clause)\n",
    "    print(\"Preprocessed Tokens:\", tokens)\n",
    "    doc.add_paragraph(\"Preprocessed Tokens: \" + str(tokens))\n",
    "\n",
    "    # Named Entity Recognition\n",
    "    ents = extract_named_entities(clause)\n",
    "    ner_text = \"Named Entities: \" + (\", \".join(ents) if ents else \"None\")\n",
    "    print(ner_text)\n",
    "    doc.add_paragraph(ner_text)\n",
    "\n",
    "    # Red flag detection\n",
    "    flagged = False\n",
    "    for flag in red_flags:\n",
    "        if flag in clause.lower():\n",
    "            flag_msg = f\"Red Flag Phrase Detected: '{flag}'\"\n",
    "            print(flag_msg)\n",
    "            doc.add_paragraph(flag_msg)\n",
    "            flagged = True\n",
    "            break\n",
    "    if not flagged:\n",
    "        print(\"No red flag phrases detected.\")\n",
    "        doc.add_paragraph(\"No red flag phrases detected.\")\n",
    "\n",
    "    # Compare with regulatory requirements\n",
    "    matched = False\n",
    "    for reg in regulatory_requirements:\n",
    "        similarity = sentence_similarity(clause.lower(), reg.lower())\n",
    "        if similarity > SIMILARITY_THRESHOLD:\n",
    "            sim_msg = f\"Matches Regulation (Similarity: {similarity:.2f}): {reg}\"\n",
    "            print(sim_msg)\n",
    "            doc.add_paragraph(sim_msg)\n",
    "            matched = True\n",
    "    if not matched:\n",
    "        print(\"No strong match found in regulatory requirements. Review recommended.\")\n",
    "        doc.add_paragraph(\"No strong match found in regulatory requirements. Review recommended.\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Save Word Document\n",
    "doc.save(my_report)\n",
    "print(f\"\\n Report saved as {my_report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
